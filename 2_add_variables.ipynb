{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is used to add the 5 variables to papers from `1_add_papers.ipynb`: `citedby-count`, `keywords`, `funding`, `ref-count`, and `ref-list`.\n",
    "\n",
    "The process may take several hours because of function `add_other_variables()` which uses Selenium to scrape data.\n",
    "\n",
    "Alternatively, you can also directly download the zip file of cleaned papers from [here](https://drive.google.com/file/d/1J1gk4LVZSjy-B2BDxy5SrwZ3LMHHmIRY/view?usp=sharing) and skip running `1_add_papers.ipynb`, `2_add_variables.ipynb`, and `3_clean_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install selenium\n",
    "!pip3 install bs4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add subject-area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ASJC.csv to ASJC.json\n",
    "# key is asjc, value is subject area\n",
    "\n",
    "asjcdict = {}\n",
    "with open(\"csv_and_json/ASJC.csv\", encoding=\"utf-8\") as csvf:\n",
    "    csvReader = csv.DictReader(csvf)\n",
    "    for row in csvReader:\n",
    "        asjcdict[row['Code']] = row['Description']\n",
    "\n",
    "with open(\"csv_and_json/ASJC.json\", \"w\", encoding=\"utf-8\") as jsonf:\n",
    "    jsonf.write(json.dumps(asjcdict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sources.csv to .json\n",
    "\n",
    "sourcesdict = {}\n",
    "with open(\"csv_and_json/sources.csv\", encoding=\"utf-8\") as csvf:\n",
    "    csvReader = csv.DictReader(csvf)\n",
    "    for row in csvReader:\n",
    "        sourcesdict[row['SourceID']] = [e.strip() for e in row['ASJC'].split(\";\")]\n",
    "\n",
    "with open(\"csv_and_json/sources.json\", \"w\", encoding=\"utf-8\") as jsonf:\n",
    "    jsonf.write(json.dumps(sourcesdict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"csv_and_json/sources.json\") as f:\n",
    "    all_sources = json.load(f)\n",
    "    \n",
    "with open(\"csv_and_json/ASJC_bycode.json\") as f:\n",
    "    asjc_bycode = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_asjc(id):\n",
    "    number = \"0\"*(5 - len(str(id))) + str(id)\n",
    "\n",
    "    with open(f\"papers/paper{number}.json\") as f:\n",
    "        paper = json.load(f)\n",
    "\n",
    "    thisasjc = []\n",
    "    source_id = paper[\"abstracts-retrieval-response\"][\"coredata\"][\"source-id\"]\n",
    "    if source_id in all_sources:\n",
    "        asjc_list = all_sources[source_id]\n",
    "        for asjc in asjc_list:\n",
    "            if asjc in asjc_bycode:\n",
    "                thisasjc.append({\n",
    "                    \"$\": asjc_bycode[asjc],\n",
    "                    \"@code\": asjc\n",
    "                })\n",
    "\n",
    "\n",
    "    paper[\"subject-areas\"] = thisasjc\n",
    "    with open(f\"papers/paper{number}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(paper, indent=4))\n",
    "        f.close()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to all papers\n",
    "for i in range(0,9020):\n",
    "    print(i , end=\" \")\n",
    "    add_asjc(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# driver & sign in to scopus\n",
    "- must run before calling add_other_variables()\n",
    "- select either Chrome or Firefox for your driver\n",
    "- type your email and password for scopus account (**NOT** CUNET password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Chrome:\n",
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Firefox:\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "\n",
    "firefox_options = FirefoxOptions()\n",
    "driver = webdriver.Firefox(options=firefox_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your email and password for scopus account here\n",
    "email = \"..@student.chula.ac.th\"\n",
    "password = \"verylongpassword\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url=\"https://www.scopus.com/home.uri\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "check_access = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"[href='/checkaccess.uri']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", check_access)\n",
    "\n",
    "accept_cookie = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"#onetrust-accept-btn-handler\")))\n",
    "driver.execute_script(\"arguments[0].click();\", accept_cookie)\n",
    "\n",
    "org_email = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#bdd-email\")))\n",
    "org_email.clear()\n",
    "org_email.send_keys(email)\n",
    "time.sleep(1)\n",
    "submit_email = driver.find_element(By.CSS_SELECTOR, \"#bdd-els-searchBtn\")\n",
    "driver.execute_script(\"arguments[0].click();\", submit_email)\n",
    "\n",
    "org_password = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#bdd-password\")))\n",
    "org_password.clear()\n",
    "org_password.send_keys(password)\n",
    "time.sleep(1)\n",
    "signin = driver.find_element(By.CSS_SELECTOR, \"#bdd-elsPrimaryBtn\")\n",
    "driver.execute_script(\"arguments[0].click();\", signin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add other variables\n",
    "- citedby-count\n",
    "- keywords\n",
    "- funding\n",
    "- ref-count\n",
    "- ref-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_other_variables(id):\n",
    "    number = \"0\"*(5 - len(str(id))) + str(id)\n",
    "    with open(f\"papers/paper{number}.json\") as f:\n",
    "        paper = json.load(f)\n",
    "        toself = paper[\"abstracts-retrieval-response\"][\"coredata\"][\"link\"][1][\"@href\"]\n",
    "        driver.get(url=toself)\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        # if error, check if you have lxml installed. if not, `!pip install lxml`\n",
    "        # or replace \"lxml with \"html.parser\" (python's parser) \n",
    "\n",
    "        if soup.select_one(\"#recordPageBoxes\") != None:\n",
    "            citedby_count = soup.select_one(\"#recordPageBoxes div div h3\").string.split()[2]\n",
    "            paper[\"citedby-count\"] = citedby_count\n",
    "\n",
    "        if soup.select(\"#funding-details div table tbody tr td p\") != None:\n",
    "            funding_list = [e.string for e in soup.select(\"#funding-details div table tbody tr td p\")]\n",
    "            # no funding detail: returns []\n",
    "            paper[\"funding\"] = funding_list\n",
    "\n",
    "        if soup.select_one(\"#author-keywords\") != None:\n",
    "            kw = soup.select_one(\"#author-keywords\").next_sibling\n",
    "            keyword_list = []\n",
    "            for e in kw.children:\n",
    "                keyword_list.append(e.span.span.string)\n",
    "            paper[\"keywords\"] = keyword_list\n",
    "\n",
    "        if soup.select_one(\"#references\") != None:\n",
    "            ref_count = soup.select_one(\"#references\").parent.text.split()[1].strip(\"()\")\n",
    "            paper[\"ref-count\"] = ref_count\n",
    "\n",
    "            rf = soup.select(\"#referenceListRowId td div\")\n",
    "            ref_list = []\n",
    "            for ref in rf:\n",
    "                if ref.attrs[\"class\"] == ['refAuthorTitle']:\n",
    "                    if ref.em != None:\n",
    "                        ref_list.append(ref.em.string)\n",
    "                elif ref.attrs[\"class\"] == ['refDocTitle', 'fontMedium']:\n",
    "                    ref_list.append(ref.a.string)\n",
    "            # len(ref_list) is not always equal to ref_count as some reference does not have a title\n",
    "            paper[\"ref-list\"] = ref_list\n",
    "        \n",
    "        with open(f\"papers/paper{number}.json\", \"w\") as f:\n",
    "            f.write(json.dumps(paper, indent=4))\n",
    "            f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to all papers\n",
    "# ~8-10 seconds per paper\n",
    "for i in range(0,9020):\n",
    "    print(i , end=\" \")\n",
    "    add_other_variables(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quit driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optional: add 3 variables (fast)\n",
    "`citedby-count`, `funding`, and `keywords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install cloudscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "scraper = cloudscraper.create_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_3_variables_fast(id):\n",
    "    number = \"0\"*(5 - len(str(id))) + str(id)\n",
    "    with open(f\"papers/paper{number}.json\") as f:\n",
    "        paper = json.load(f)\n",
    "        toself = paper[\"abstracts-retrieval-response\"][\"coredata\"][\"link\"][1][\"@href\"]\n",
    "        page = scraper.get(toself).text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        # if error, try \"html.parser\" instead of \"lxml\"\n",
    "\n",
    "        if soup.select_one(\"#recordPageBoxes\") != None:\n",
    "            citedby_count = soup.select_one(\"#recordPageBoxes div div h3\").string.split()[2]\n",
    "            paper[\"citedby-count\"] = citedby_count\n",
    "\n",
    "        if soup.select(\"#fundingDetails table tbody tr\") != None:\n",
    "            funding_list = []\n",
    "            count = 0\n",
    "            for td in soup.select(\"#fundingDetails table tbody tr td\"):\n",
    "                if td.string != None and count%3 == 0: \n",
    "                    funding_list.append(td.string)\n",
    "                count += 1\n",
    "            # no funding detail: returns []\n",
    "            paper[\"funding\"] = funding_list\n",
    "\n",
    "        if soup.select_one(\"#authorKeywords\") != None:\n",
    "            kw = soup.select(\"#authorKeywords span\")\n",
    "            keyword_list = []\n",
    "            for e in kw:\n",
    "                keyword_list.append(e.string)\n",
    "            paper[\"keywords\"] = keyword_list\n",
    "\n",
    "\n",
    "        with open(f\"papers/paper{number}.json\", \"w\") as f:\n",
    "            f.write(json.dumps(paper, indent=4))\n",
    "            f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to all papers\n",
    "# ~0.5 - 1 second per paper\n",
    "for i in range(0,9020):\n",
    "    print(i , end=\" \")\n",
    "    add_3_variables_fast(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_sci_midterm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
