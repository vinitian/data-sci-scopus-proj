{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `fundingMLP.model`\n",
    "- If you already have the .model file, you can skip this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sorted_papers/'\n",
    "fileNames = [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "print('total:', len(fileNames))\n",
    "for i in range(len(fileNames)):\n",
    "    print('creating', i)\n",
    "    with open(path+fileNames[i], 'r', encoding=\"utf8\") as file:\n",
    "        data = json.load(file)\n",
    "        id = data['eid']\n",
    "        quatile = ceil(int(data['cover-date'][5:7]) / 3)\n",
    "        fund = data['funding']\n",
    "        field = {'authorCount': len(data['authors']), 'refCount': data['ref-count'], 'citedByCount': data['citedby-count'], 'quatile':quatile, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, 'funded': False}\n",
    "        dic[id] = field\n",
    "        for i in data['subject-areas']:\n",
    "            code = i['@code'][:2]\n",
    "            if dic[id][code] == 0:\n",
    "                if fund != []:\n",
    "                    dic[id]['funded'] = True\n",
    "                dic[id][code] += 1\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic, orient='index')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./predictFundingDf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case already have predictFundingDf.csv\n",
    "df = pd.read_csv('./predictFundingDf.csv')\n",
    "df.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "2-s2.0-85146754852     True\n",
      "2-s2.0-85045872589    False\n",
      "2-s2.0-85051658859    False\n",
      "2-s2.0-84992217873     True\n",
      "2-s2.0-85087089727    False\n",
      "                      ...  \n",
      "2-s2.0-85006952323     True\n",
      "2-s2.0-84927174037    False\n",
      "2-s2.0-85089272667     True\n",
      "2-s2.0-85007005033     True\n",
      "2-s2.0-85016087590     True\n",
      "Name: funded, Length: 5841, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "x = df.drop(['funded'], axis=1)\n",
    "y = df['funded']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, stratify=y, test_size = 0.2, random_state= 33799)\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'alpha': 0.001, 'batch_size': 256, 'hidden_layer_sizes': (150,), 'random_state': 33799}\n",
      "[[3022  549]\n",
      " [ 929 1341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.7095    0.5907    0.6447      2270\n",
      "        True     0.7649    0.8463    0.8035      3571\n",
      "\n",
      "    accuracy                         0.7470      5841\n",
      "   macro avg     0.7372    0.7185    0.7241      5841\n",
      "weighted avg     0.7434    0.7470    0.7418      5841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasir\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=dict(\n",
    "        hidden_layer_sizes=[(100,75,),(100,75,50),(150,),(100,100)],\n",
    "        activation=['logistic'],\n",
    "        batch_size=[256,512],\n",
    "        random_state=[33799],\n",
    "        alpha=[0.0001,0.0005, 0.001,0.002]\n",
    "    ),\n",
    "\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[True,False]))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./fundingMLP.model','wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding scraped dataset, fundingMLP1.model is:\n",
    "\n",
    "{'activation': 'logistic', 'alpha': 0.001, 'batch_size': 256, 'hidden_layer_sizes': (150,), 'random_state': 33799}\n",
    "```\n",
    "[[3022  549]\n",
    " [ 929 1341]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.7095    0.5907    0.6447      2270\n",
    "        True     0.7649    0.8463    0.8035      3571\n",
    "\n",
    "    accuracy                         0.7470      5841\n",
    "   macro avg     0.7372    0.7185    0.7241      5841\n",
    "weighted avg     0.7434    0.7470    0.7418      5841\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'activation': 'logistic', 'alpha': 0.0005, 'batch_size': 512, 'hidden_layer_sizes': (100, 75), 'random_state': 33799}\n",
    "```\n",
    "[[2525  260]\n",
    " [ 717  541]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6754    0.4300    0.5255      1258\n",
    "        True     0.7788    0.9066    0.8379      2785\n",
    "\n",
    "    accuracy                         0.7583      4043\n",
    "   macro avg     0.7271    0.6683    0.6817      4043\n",
    "weighted avg     0.7467    0.7583    0.7407      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fundingMLP.model\n",
    "{'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 512, 'hidden_layer_sizes': (100, 50, 25), 'random_state': 33799}\n",
    "```\n",
    "[[2480  305]\n",
    " [ 675  583]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6565    0.4634    0.5433      1258\n",
    "        True     0.7861    0.8905    0.8350      2785\n",
    "\n",
    "    accuracy                         0.7576      4043\n",
    "   macro avg     0.7213    0.6770    0.6892      4043\n",
    "weighted avg     0.7458    0.7576    0.7443      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'activation': 'logistic', 'alpha': 0.002, 'batch_size': 512, 'hidden_layer_sizes': (100, 75, 50), 'random_state': 33799}\n",
    "```\n",
    "[[2496  289]\n",
    " [ 690  568]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6628    0.4515    0.5371      1258\n",
    "        True     0.7834    0.8962    0.8360      2785\n",
    "\n",
    "    accuracy                         0.7579      4043\n",
    "   macro avg     0.7231    0.6739    0.6866      4043\n",
    "weighted avg     0.7459    0.7579    0.7430      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'activation': 'logistic', 'alpha': 0.002, 'batch_size': 256, 'hidden_layer_sizes': (150,), 'random_state': 33799}\n",
    "```\n",
    "[[2500  285]\n",
    " [ 710  548]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6579    0.4356    0.5242      1258\n",
    "        True     0.7788    0.8977    0.8340      2785\n",
    "\n",
    "    accuracy                         0.7539      4043\n",
    "   macro avg     0.7183    0.6666    0.6791      4043\n",
    "weighted avg     0.7412    0.7539    0.7376      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scoring f1\n",
    "{'activation': 'logistic', 'alpha': 0.002, 'batch_size': 512, 'hidden_layer_sizes': (100, 100), 'random_state': 33799}\n",
    "```\n",
    "[[2530  255]\n",
    " [ 748  510]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6667    0.4054    0.5042      1258\n",
    "        True     0.7718    0.9084    0.8346      2785\n",
    "\n",
    "    accuracy                         0.7519      4043\n",
    "   macro avg     0.7192    0.6569    0.6694      4043\n",
    "weighted avg     0.7391    0.7519    0.7318      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.002, 'hidden_layer_sizes': (150,), 'random_state': 33799}\n",
    "```\n",
    "[[2374  411]\n",
    " [ 623  635]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6071    0.5048    0.5512      1258\n",
    "        True     0.7921    0.8524    0.8212      2785\n",
    "\n",
    "    accuracy                         0.7442      4043\n",
    "   macro avg     0.6996    0.6786    0.6862      4043\n",
    "weighted avg     0.7345    0.7442    0.7372      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.002, 'hidden_layer_sizes': (150, 150), 'random_state': 33799}\n",
    "```\n",
    "[[2420  365]\n",
    " [ 702  556]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6037    0.4420    0.5103      1258\n",
    "        True     0.7751    0.8689    0.8194      2785\n",
    "\n",
    "    accuracy                         0.7361      4043\n",
    "   macro avg     0.6894    0.6555    0.6648      4043\n",
    "weighted avg     0.7218    0.7361    0.7232      4043\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'random_state': 33799}\n",
    "```\n",
    "[[2495  290]\n",
    " [ 725  533]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False     0.6476    0.4237    0.5123      1258\n",
    "        True     0.7748    0.8959    0.8310      2785\n",
    "\n",
    "    accuracy                         0.7489      4043\n",
    "   macro avg     0.7112    0.6598    0.6716      4043\n",
    "weighted avg     0.7353    0.7489    0.7318      4043\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
